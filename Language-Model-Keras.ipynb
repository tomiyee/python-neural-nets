{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles Importing all the necessary libraries\n",
    "import itertools\n",
    "import h5py\n",
    "import numpy as np\n",
    "import string\n",
    "import keras\n",
    "from keras.layers import Input, Embedding, merge, Flatten, Reshape, Lambda, LSTM, Dropout\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepares the Data Set to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes Removed: 323\n",
      "Number of Sentences: 7441\n",
      "Vocabulary: 6463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dankmaster69/python-neural-nets/venv/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#imports a massive dataset of sentences found on wikipedia\n",
    "with open('ignored_assets/lang-train-data-angelas-ashes.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line,\n",
    "# also strips the punctuation\n",
    "sentences = [x.strip().translate(None, string.punctuation) for x in content] \n",
    "\n",
    "lemma = lambda x: x.strip().lower().split(' ')\n",
    "sentences_lemmatized = [lemma(sentence) for sentence in sentences]\n",
    "words = set(itertools.chain(*sentences_lemmatized))\n",
    "# set(['boy', 'fed', 'ate', 'cat', 'kicked', 'hat'])\n",
    "\n",
    "# dictionaries for converting words to integers and vice versa\n",
    "word2idx = dict((v, i) for i, v in enumerate(words))\n",
    "idx2word = list(words)\n",
    "\n",
    "# convert the sentences a numpy array\n",
    "to_idx = lambda x: [word2idx[word] for word in x]\n",
    "sentences_idx = [to_idx(sentence) for sentence in sentences_lemmatized]\n",
    "# Sets the maximum word length of each sentence\n",
    "max_len = 40\n",
    "# a list of all the indices I remove that are longer than max_len\n",
    "indices_removed = []\n",
    "# If the sentence is too long, good by\n",
    "for i in range(len(sentences_idx)-1, -1, -1):\n",
    "    if len(sentences_idx[i]) > max_len:\n",
    "        indices_removed = indices_removed + [i]\n",
    "        sentences_idx.pop(i)\n",
    "    elif len(sentences_idx[i]) < max_len:\n",
    "        sentences_idx[i] = [0] * (max_len - len(sentences_idx[i])) + sentences_idx[i]\n",
    "print \"Indexes Removed: {}\".format(len(indices_removed))\n",
    "print \"Number of Sentences: {}\".format(len(sentences_idx))\n",
    "print \"Vocabulary: {}\".format(len(word2idx))\n",
    "sentences_array = np.asarray(sentences_idx, dtype='int32')\n",
    "\n",
    "# Prepares the datasets as input and output\n",
    "dataX = np.array(sentences_array[:len(sentences_array)-1]).copy()\n",
    "dataY = np.array(sentences_array[1:]).copy()\n",
    "\n",
    "# scales the output\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataY = scaler.fit_transform(dataY)\n",
    "# reshapes the dataY\n",
    "new_dataY = dataY.reshape((1,) + dataY.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create and Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 2/2\n",
      ": [ 0.01451545  0.02909766 -0.01125624 -0.00711956  0.0109189  -0.00510339\n",
      " -0.01580079  0.00141494  0.01698543  0.00884955  0.00315764 -0.0104336\n",
      "  0.01034257  0.00877095 -0.01010862 -0.02148722 -0.00934169 -0.00330972\n",
      " -0.00472692  0.00025703  0.0112626   0.01483593 -0.00788761  0.02443505\n",
      " -0.01868114 -0.01152818 -0.03485267  0.03709104 -0.00661962  0.01231158\n",
      "  0.00197059  0.01476801 -0.01198881  0.00303477  0.00891626 -0.00378854\n",
      " -0.00682382  0.03451822  0.01305496 -0.01244588  0.00304619 -0.03807345\n",
      " -0.00813417  0.02238745 -0.00720909  0.02882003 -0.01264686  0.01116628\n",
      "  0.00513404 -0.02124971 -0.00999493  0.01704622  0.00024498 -0.0195619\n",
      " -0.00863702 -0.03711805 -0.00237693  0.0025817  -0.02479479 -0.0092837\n",
      "  0.02818282  0.0244569  -0.00997254  0.00492533 -0.00369392  0.02984793\n",
      " -0.01286931 -0.01907092 -0.03457579  0.00827978  0.01107627  0.00301307\n",
      " -0.00487189 -0.01417233 -0.00283344 -0.00413371  0.0072307  -0.00080106\n",
      "  0.01267176 -0.00801167  0.01850155 -0.00659078  0.00976997  0.00297864\n",
      "  0.00521809 -0.02254621  0.03161955  0.01690294  0.02202942 -0.01546109\n",
      "  0.0010473   0.03087882  0.01515964  0.02597251 -0.01738573  0.00399726\n",
      " -0.01207993  0.02190529  0.00471075 -0.02240158 -0.00187942 -0.02941869\n",
      " -0.00071725 -0.00627396  0.00377851  0.03172642  0.02874216  0.00806429\n",
      "  0.01461219  0.02134343  0.00461402 -0.01475393 -0.01590233  0.00992836\n",
      " -0.00444699  0.0027193   0.0080964   0.00634554  0.00630664  0.00609414\n",
      "  0.01627789 -0.00045159 -0.02137002  0.01584218 -0.01199399 -0.01656564\n",
      " -0.00577267  0.01519799 -0.00133258  0.00998595 -0.02739538  0.01259679\n",
      "  0.00085946 -0.02245553  0.01228879 -0.01029386 -0.01252084  0.00713811\n",
      " -0.00154951 -0.00753633  0.01122301  0.00322849  0.00438689  0.01829275\n",
      "  0.03382029  0.00633237  0.00096088 -0.00504682  0.02074171 -0.01477809]\n",
      "raining: [-0.01379164 -0.02624978 -0.20597821  0.12582773 -0.17578083  0.01785628\n",
      " -0.0629705  -0.23613401  0.00244277  0.15278001 -0.06991607  0.03066766\n",
      "  0.00353052 -0.02816928 -0.04301174 -0.22060031 -0.01543033  0.0090648\n",
      " -0.0049531   0.02111887 -0.14021353 -0.01566326 -0.13554661 -0.21376438\n",
      " -0.00672954 -0.03475117  0.26130319  0.05815227 -0.12914465 -0.0281754\n",
      " -0.09037472  0.02416461  0.07680427  0.34952995 -0.028839   -0.10280042\n",
      " -0.03432472 -0.19877172 -0.03428091 -0.14351502  0.15060598  0.08290378\n",
      "  0.17803702  0.11858863  0.12259291  0.12369901 -0.02243579  0.1048584\n",
      " -0.04344181 -0.13820855 -0.11091676 -0.1355833   0.11132282  0.16734773\n",
      "  0.04207245 -0.1464871   0.00738886  0.30432621  0.20117629  0.09888759\n",
      " -0.01041433 -0.06488217 -0.21180071  0.11067402 -0.31504095 -0.30923086\n",
      " -0.18505883  0.01260567  0.1817545   0.45489961  0.21780787 -0.04780649\n",
      "  0.25730827  0.05001682 -0.18223895 -0.17451057 -0.07229085  0.01096414\n",
      "  0.22082332  0.02658673 -0.06186258 -0.09743479 -0.04724539  0.07439993\n",
      " -0.21638051  0.00064024  0.06222576  0.2370442  -0.45470724  0.02871558\n",
      "  0.21140997 -0.22148053 -0.09798881  0.08325554  0.10019121  0.03275124\n",
      "  0.34171337  0.15588789  0.1385742   0.04238594  0.04302426 -0.12314354\n",
      "  0.11577019 -0.31527051  0.03882352 -0.09610851  0.24200767 -0.26532108\n",
      "  0.03278641 -0.05462226 -0.16986345 -0.04166956  0.00569923  0.01256739\n",
      "  0.27642199  0.07733403  0.16493432 -0.07956082 -0.17822407  0.10546068\n",
      "  0.01621653  0.17865856  0.24134724 -0.03526975  0.13056247 -0.23689143\n",
      " -0.25728947  0.02316288 -0.08191635 -0.083217    0.30409876 -0.00916812\n",
      "  0.03093803  0.05699369  0.09437695  0.05393542 -0.07350817 -0.0335969\n",
      " -0.05222714 -0.00453698 -0.36209765 -0.26054344 -0.04247232 -0.37128296\n",
      "  0.00875883  0.21820593 -0.12010567  0.01079655  0.12261303 -0.10860916]\n",
      "Evaluation of the Model\n",
      "7392/7440 [============================>.] - ETA: 0s0.225529493632\n",
      "Saving the Weights\n"
     ]
    }
   ],
   "source": [
    "n_words = len(words)\n",
    "n_embed_dims = 150\n",
    "\n",
    "# put together a model to predict\n",
    "input_sentence = Input(shape=(max_len,), dtype='int32')\n",
    "input_embedding = Embedding(n_words, n_embed_dims)(input_sentence)\n",
    "output = SimpleRNN(max_len)(input_embedding)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.abs(y_true - y_pred))\n",
    "\n",
    "model = Model(inputs=[input_sentence], outputs=[output])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0), loss=custom_loss)\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "\n",
    "# fit the model to predict what color each person is\n",
    "model.fit(dataX, dataY, epochs=2, verbose=3)\n",
    "embeddings = model.layers[1].get_weights()\n",
    "\n",
    "# print out the embedding vector associated with each word\n",
    "for i in range(2):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[0][i]))\n",
    "    \n",
    "print \"Evaluation of the Model\"\n",
    "print model.evaluate(dataX, dataY)\n",
    "print \"Saving the Weights\"\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Training For The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19s - loss: 0.2247\n",
      "Epoch 2/30\n",
      "19s - loss: 0.2210\n",
      "Epoch 3/30\n",
      "19s - loss: 0.2180\n",
      "Epoch 4/30\n",
      "19s - loss: 0.2159\n",
      "Epoch 5/30\n",
      "19s - loss: 0.2141\n",
      "Epoch 6/30\n",
      "19s - loss: 0.2126\n",
      "Epoch 7/30\n",
      "19s - loss: 0.2113\n",
      "Epoch 8/30\n",
      "19s - loss: 0.2102\n",
      "Epoch 9/30\n",
      "19s - loss: 0.2092\n",
      "Epoch 10/30\n",
      "19s - loss: 0.2083\n",
      "Epoch 11/30\n",
      "19s - loss: 0.2076\n",
      "Epoch 12/30\n",
      "19s - loss: 0.2069\n",
      "Epoch 13/30\n",
      "19s - loss: 0.2062\n",
      "Epoch 14/30\n",
      "19s - loss: 0.2056\n",
      "Epoch 15/30\n",
      "19s - loss: 0.2051\n",
      "Epoch 16/30\n",
      "19s - loss: 0.2045\n",
      "Epoch 17/30\n",
      "19s - loss: 0.2041\n",
      "Epoch 18/30\n",
      "19s - loss: 0.2036\n",
      "Epoch 19/30\n",
      "19s - loss: 0.2032\n",
      "Epoch 20/30\n",
      "19s - loss: 0.2028\n",
      "Epoch 21/30\n",
      "19s - loss: 0.2023\n",
      "Epoch 22/30\n",
      "19s - loss: 0.2021\n",
      "Epoch 23/30\n",
      "19s - loss: 0.2019\n",
      "Epoch 24/30\n",
      "19s - loss: 0.2013\n",
      "Epoch 25/30\n",
      "19s - loss: 0.2011\n",
      "Epoch 26/30\n",
      "19s - loss: 0.2008\n",
      "Epoch 27/30\n",
      "19s - loss: 0.2004\n",
      "Epoch 28/30\n",
      "19s - loss: 0.2002\n",
      "Epoch 29/30\n",
      "19s - loss: 0.2000\n",
      "Epoch 30/30\n",
      "19s - loss: 0.1997\n",
      "7360/7440 [============================>.] - ETA: 0s  0.198619256289\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataX, dataY, epochs=30, batch_size=16, verbose=2)\n",
    "print \"  {}\".format(model.evaluate(dataX, dataY))\n",
    "model.save_weights('model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Epoch 2/4\n",
      "Epoch 3/4\n",
      "Epoch 4/4\n",
      ": [ -7.52860755e-02  -4.54015285e-02  -4.58094329e-02   8.84827878e-03\n",
      "  -8.48692900e-04  -3.17476653e-02  -1.13650709e-02   6.56244531e-02\n",
      "   6.53840974e-03   6.65657148e-02  -2.31543127e-02  -3.21851298e-02\n",
      "  -5.29217646e-02   1.71483925e-03   1.58685390e-02   1.47633646e-02\n",
      "  -3.10055520e-02   2.67946278e-03  -4.41819243e-03   1.17825922e-02\n",
      "   3.26833390e-02   6.82228524e-03  -2.40664147e-02   1.81059614e-02\n",
      "   4.85693328e-02   4.03854847e-02   5.97351231e-02   2.43128533e-03\n",
      "  -2.56353430e-02   1.97669603e-02  -8.07724521e-03   6.48374995e-03\n",
      "  -6.76449202e-03   3.24921831e-02   8.01629853e-03   9.09802562e-04\n",
      "  -1.93910580e-02  -2.17047911e-02  -4.88672033e-02  -4.92293611e-02\n",
      "  -1.37611022e-02   4.78589945e-02   1.62587315e-02  -1.04369866e-02\n",
      "  -3.82489036e-03  -7.70846556e-04   6.44029975e-02   6.63364481e-04\n",
      "   3.35666910e-02  -5.23372591e-02   6.23806678e-02  -1.97675209e-02\n",
      "  -1.34685580e-02  -2.47143134e-02  -3.12603428e-03   3.02405693e-02\n",
      "  -5.43108303e-03  -4.86856047e-03  -6.16468256e-03  -6.56778291e-02\n",
      "   2.80749761e-02   1.68174058e-02   5.01717953e-03   3.28464657e-02\n",
      "   4.94441949e-02   5.38286706e-03  -5.35058379e-02   1.32295350e-02\n",
      "   5.36481803e-03   4.23565581e-02   4.10231277e-02   3.82129736e-02\n",
      "  -1.79277174e-02   7.41770416e-02   3.89268138e-02   6.30560368e-02\n",
      "   1.96178183e-02   2.58695558e-02   2.65420005e-02  -5.03315330e-02\n",
      "  -1.02500185e-01  -2.38070134e-02  -3.76419537e-02  -4.41217162e-02\n",
      "   3.43981870e-02   3.58078778e-02  -4.22149971e-02  -1.95316840e-02\n",
      "   6.25744089e-02   1.94089115e-02   3.71261649e-02  -6.18134066e-02\n",
      "  -1.24759059e-02  -2.72412086e-03   1.32394698e-03  -3.53833772e-02\n",
      "   3.20545696e-02  -1.27512626e-02   5.22488775e-03   7.34908879e-02\n",
      "  -7.43532702e-02  -5.41725941e-02  -5.96406125e-02  -4.04142924e-02\n",
      "  -5.90195432e-02  -5.93596809e-02  -9.64786485e-03  -4.89757955e-02\n",
      "   1.59669612e-02   5.90473264e-02  -2.10292041e-02   2.24312451e-02\n",
      "  -3.36811095e-02   1.33087020e-02   1.85255893e-02  -7.02643767e-02\n",
      "  -3.66767012e-02   4.34864201e-02  -7.00375140e-02   4.09763604e-02\n",
      "  -9.40893218e-03  -4.01273556e-03   5.62449582e-02   6.74005076e-02\n",
      "  -1.12204151e-02  -1.65602509e-02  -2.18027793e-02  -1.45977745e-02\n",
      "  -9.77925738e-05   4.88026515e-02   8.60865600e-03  -2.01022197e-02\n",
      "  -3.49305919e-03   1.82843823e-02   4.55038026e-02   2.97041107e-02\n",
      "   1.50327652e-03   2.96132974e-02   3.24154645e-02   4.52071764e-02\n",
      "   1.75824668e-03  -2.28237566e-02   2.75641773e-02  -1.31969843e-02\n",
      "  -1.74199846e-02  -3.88109609e-02  -4.10306118e-02  -4.51851543e-03\n",
      "  -1.29248491e-02   4.94936444e-02]\n",
      "raining: [  2.17662882e-02  -3.22358608e-02   3.84049192e-02  -1.48130795e-02\n",
      "  -3.91182229e-02   1.98821183e-02   7.26884883e-03   3.82590806e-04\n",
      "   4.33988962e-03   5.22758663e-02   3.38371918e-02  -1.85643565e-02\n",
      "  -5.12135774e-02   8.95453151e-03  -4.86068102e-03   2.92333923e-02\n",
      "   1.38899060e-02  -2.50524767e-02   1.46875326e-02  -1.88776404e-02\n",
      "   1.89123545e-02   3.74245308e-02  -1.69121902e-02   1.29888356e-02\n",
      "  -2.99088471e-02   4.72432673e-02   6.61857519e-03   2.40509436e-02\n",
      "  -2.48108860e-02   5.15524894e-02  -4.37095501e-02  -3.79354320e-02\n",
      "  -3.69691327e-02   2.84210201e-02   3.42914835e-02   3.90065983e-02\n",
      "  -5.20513654e-02   1.15966611e-02  -3.85929756e-02   1.01527646e-02\n",
      "  -1.03866849e-02   1.81655400e-02  -4.30043489e-02   2.68924739e-02\n",
      "  -4.16258052e-02   1.37270372e-02   3.36869285e-02  -4.07314412e-02\n",
      "  -4.08863984e-02  -2.18793787e-02  -2.93575600e-02  -4.42397520e-02\n",
      "  -6.75795600e-04   1.86134577e-02  -1.65594183e-02  -3.04894894e-02\n",
      "  -3.66011560e-02  -2.19888277e-02   1.81427728e-02   1.51306102e-02\n",
      "   4.40629758e-02  -3.66290063e-02   1.64120886e-02  -3.52665521e-02\n",
      "  -9.02011991e-04  -2.62715667e-02   2.34425012e-02  -1.82825290e-02\n",
      "   2.04689670e-02  -3.76056135e-02   3.86128090e-02  -4.91567254e-02\n",
      "   3.90621996e-03   1.20502263e-02  -8.91838595e-03   4.74537760e-02\n",
      "  -1.67961195e-02   1.09253358e-02  -3.39184166e-03  -8.19834508e-03\n",
      "  -3.14407721e-02   3.85490693e-02   3.05205770e-02   6.03682594e-03\n",
      "  -3.88378799e-02  -1.42913461e-02   3.43349129e-02   3.30614261e-02\n",
      "  -1.39089068e-02   1.76488087e-02   1.11607956e-02   3.96731421e-02\n",
      "  -5.02227107e-04  -3.56954783e-02   1.73275247e-02  -2.37809587e-03\n",
      "  -1.09385117e-03  -1.53382681e-03  -4.42829318e-02   5.17721511e-02\n",
      "  -8.31692014e-04   3.75299603e-02  -1.41658532e-02  -5.56084886e-02\n",
      "   3.05505767e-02  -3.90999690e-02  -9.46693402e-03  -3.58318165e-02\n",
      "   1.78119820e-02  -2.10042228e-03   2.00573895e-02  -3.01384013e-02\n",
      "  -5.02838604e-02  -3.62950400e-03  -3.50329140e-03  -3.84560376e-02\n",
      "   1.53800258e-02   4.02755104e-05   2.92134397e-02  -2.90230345e-02\n",
      "  -1.85889960e-03  -3.48939188e-02   3.96542735e-02  -1.00900168e-02\n",
      "   2.05992046e-03  -4.42526415e-02  -1.80659816e-02  -3.14899907e-02\n",
      "   3.56562808e-02   4.08458933e-02   1.63240619e-02   7.38642737e-03\n",
      "   2.14235988e-02   2.74679400e-02   1.06987488e-02   3.83791467e-03\n",
      "  -3.07810921e-02   2.81800386e-02  -1.72081366e-02  -2.60625910e-02\n",
      "   2.21095681e-02  -1.99711565e-02   2.62284791e-03   1.88709609e-02\n",
      "   3.98966074e-02  -4.55852263e-02   1.96404513e-02   8.03712383e-03\n",
      "   3.77115272e-02  -9.66952369e-03]\n",
      "7360/7440 [============================>.] - ETA: 0sEvaluation: -8155.56841923\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataX, dataY, epochs=4, batch_size=64, verbose=3)\n",
    "embeddings = model.layers[1].get_weights()\n",
    "\n",
    "# print out the embedding vector associated with each word\n",
    "for i in range(2):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[0][i]))\n",
    "\n",
    "print 'Evaluation: {}'.format(model.evaluate(dataX, dataY))\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to test the model with some custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        ,  0.        , -0.        ,  0.        ,  0.00316837,\n",
       "        -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "         0.08428954,  0.28899291,  0.        ,  0.        ,  0.        ,\n",
       "        -0.31553316,  0.03101788,  0.        ,  0.        , -0.        ,\n",
       "        -0.        ,  0.        ,  0.13992527, -0.11859532,  0.        ,\n",
       "         0.        ,  0.        ,  0.01655224, -0.        ,  0.03247942,\n",
       "        -0.        ,  0.01039564, -0.        ,  0.        ,  0.19620955,\n",
       "         0.        ,  0.        ,  0.18380126,  0.12647456, -0.        ,\n",
       "         0.        ,  0.29543972,  0.59864187,  0.29531297,  0.28910464,\n",
       "        -0.        ,  0.65704238,  0.83109629,  0.65468234,  0.56219828,\n",
       "        -0.        ,  0.46520701,  0.54404628,  1.        ,  0.70375729,\n",
       "         0.84097189,  1.        ,  1.        ,  1.        , -0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        , -0.        ,  1.        , -0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        -0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = [0] * (max_len - 3) + [word2idx['i'], word2idx['love'], word2idx['you']]\n",
    "model.predict(np.array(inp).reshape(1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Model\n",
    "This is how you export the model into a json file in order to be imported later. Then you export the model's weights. Later on in other experiments, you could effectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Model\n",
    "This is how you import the model from a json file and the weights so that you don't need to train it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
