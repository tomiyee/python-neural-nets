{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handles Importing all the necessary libraries\n",
    "import itertools\n",
    "import h5py\n",
    "import numpy as np\n",
    "import string\n",
    "from keras.layers import Input, Embedding, merge, Flatten, Reshape, Lambda, LSTM, Dropout\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepares the Data Set to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes Removed: 323\n",
      "Number of Sentences: 7441\n",
      "Vocabulary: 6463\n"
     ]
    }
   ],
   "source": [
    "#imports a massive dataset of sentences found on wikipedia\n",
    "with open('ignored_assets/lang-train-data-angelas-ashes.txt') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line,\n",
    "# also strips the punctuation\n",
    "sentences = [x.strip().translate(None, string.punctuation) for x in content] \n",
    "\n",
    "lemma = lambda x: x.strip().lower().split(' ')\n",
    "sentences_lemmatized = [lemma(sentence) for sentence in sentences]\n",
    "words = set(itertools.chain(*sentences_lemmatized))\n",
    "# set(['boy', 'fed', 'ate', 'cat', 'kicked', 'hat'])\n",
    "\n",
    "# dictionaries for converting words to integers and vice versa\n",
    "word2idx = dict((v, i) for i, v in enumerate(words))\n",
    "idx2word = list(words)\n",
    "\n",
    "# convert the sentences a numpy array\n",
    "to_idx = lambda x: [word2idx[word] for word in x]\n",
    "sentences_idx = [to_idx(sentence) for sentence in sentences_lemmatized]\n",
    "# Sets the maximum word length of each sentence\n",
    "max_len = 40\n",
    "# a list of all the indices I remove that are longer than max_len\n",
    "indices_removed = []\n",
    "# If the sentence is too long, good by\n",
    "for i in range(len(sentences_idx)-1, -1, -1):\n",
    "    if len(sentences_idx[i]) > max_len:\n",
    "        indices_removed = indices_removed + [i]\n",
    "        sentences_idx.pop(i)\n",
    "    elif len(sentences_idx[i]) < max_len:\n",
    "        sentences_idx[i] = [0] * (max_len - len(sentences_idx[i])) + sentences_idx[i]\n",
    "print \"Indexes Removed: {}\".format(len(indices_removed))\n",
    "print \"Number of Sentences: {}\".format(len(sentences_idx))\n",
    "print \"Vocabulary: {}\".format(len(word2idx))\n",
    "sentences_array = np.asarray(sentences_idx, dtype='int32')\n",
    "\n",
    "# Prepares the datasets as input and output\n",
    "dataX = np.array(sentences_array[:len(sentences_array)-1]).copy()\n",
    "dataY = np.array(sentences_array[1:]).copy()\n",
    "\n",
    "# scales the output\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataY = scaler.fit_transform(orig_dataY)\n",
    "# reshapes the dataY\n",
    "new_dataY = dataY.reshape((1,) + dataY.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create and Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 2/2\n",
      ": [-0.01661432 -0.00696552 -0.0105041  -0.02706422 -0.032588    0.05675888\n",
      " -0.03586446 -0.04565528 -0.05752029  0.05073267 -0.01106296  0.03993874\n",
      " -0.01543578 -0.03887717  0.0067728  -0.00853418  0.00094086  0.02676368\n",
      "  0.03613407  0.03612905 -0.03502238  0.03959559 -0.0372909   0.03599412\n",
      " -0.0669523   0.04242242  0.00354336  0.02336046  0.04605285  0.0130783\n",
      "  0.00475045 -0.0038187  -0.01047738 -0.01872551 -0.02171952  0.04167085\n",
      "  0.01607439  0.03657294  0.03171887  0.06265767  0.06442416  0.04387547\n",
      " -0.06585166  0.00996963 -0.04687055 -0.04212037  0.02033991  0.04103671\n",
      " -0.02860193  0.03982403  0.01655041  0.0280925  -0.02766712 -0.02552239\n",
      "  0.06964874  0.03138467  0.02922536  0.01836007  0.03308022 -0.01765107\n",
      " -0.03590905 -0.0274533  -0.05558426  0.00449759 -0.00061701 -0.06623379\n",
      " -0.00473527 -0.00820161  0.04665337 -0.00797568 -0.00082443  0.04642951\n",
      "  0.0338419  -0.02822362  0.0490189   0.04460569  0.01967261  0.02357109\n",
      "  0.04668439 -0.02029392 -0.02746763 -0.00517707 -0.00336662  0.01033786\n",
      "  0.04366892 -0.0337612   0.02403264  0.03755918 -0.06010055  0.07474304\n",
      " -0.02392891  0.02891101 -0.03263187 -0.05838239  0.02664845 -0.02441754\n",
      "  0.01751766 -0.02447459  0.00519184 -0.02018297  0.0005729  -0.02225801\n",
      " -0.04465821  0.02099142  0.05567817 -0.0194147  -0.07898325 -0.06077303\n",
      " -0.00183605 -0.01600812  0.00885438 -0.02314052  0.01756101 -0.02699089\n",
      " -0.02793303 -0.04571541 -0.0461524  -0.00125116  0.01854526  0.03490044\n",
      " -0.03258156  0.01735761 -0.01723669 -0.05369456 -0.023334   -0.01534351\n",
      "  0.06051348  0.01849113  0.01602193 -0.02073958  0.025836    0.0338813\n",
      "  0.00640749  0.0388341   0.04685242  0.01339539  0.01696614  0.03796529\n",
      " -0.05958304  0.03000293  0.06241964 -0.04924465 -0.07217725 -0.03783439\n",
      "  0.02466426 -0.0098648   0.09183216 -0.03555427  0.07516596 -0.00793632]\n",
      "raining: [-0.03209451 -0.03027797  0.02047032 -0.03783487 -0.0007022  -0.03381275\n",
      "  0.00860413 -0.03942574 -0.00230004 -0.05619187 -0.03521125 -0.02871781\n",
      "  0.03182665 -0.04164368 -0.00813743 -0.0188859  -0.01009523 -0.04740722\n",
      "  0.02068238 -0.03160163 -0.01108086 -0.02051415  0.00432835 -0.05628084\n",
      "  0.01300932  0.01984564 -0.05309011  0.00640229  0.04953823 -0.03537283\n",
      " -0.01364608 -0.00089673 -0.03440841 -0.02961814 -0.03671736 -0.03531088\n",
      " -0.01046344  0.04635959 -0.02644371  0.03460193 -0.0403103  -0.047252\n",
      " -0.04435896  0.00213622  0.01821368  0.02039727  0.02537236  0.0434767\n",
      "  0.00176677 -0.04612778  0.01280997  0.02722647 -0.03532573  0.0021796\n",
      "  0.0111005   0.01175886  0.04464259 -0.03079677 -0.00161142 -0.04174928\n",
      " -0.050103   -0.05672535  0.02000732  0.01536968 -0.02568636 -0.01670821\n",
      "  0.02757157 -0.01659904 -0.03904036  0.04341792  0.0309006   0.02535273\n",
      "  0.00167371  0.04065899 -0.035805    0.02065271 -0.01349153 -0.04771359\n",
      " -0.01497272  0.02538515  0.04363372 -0.00591771  0.00203686 -0.0106729\n",
      "  0.02083159  0.04060485 -0.03211764  0.04327122 -0.05016158 -0.02720351\n",
      "  0.01886605  0.04615162 -0.03825267  0.04317593  0.02097059 -0.04337865\n",
      "  0.01779974 -0.00570416 -0.04392873 -0.01276515  0.03331962  0.02413517\n",
      " -0.03798058 -0.0097873  -0.04755567  0.00294045  0.03187104  0.01512902\n",
      "  0.01172069 -0.00390264 -0.02394438  0.02440928 -0.02543923  0.03948226\n",
      " -0.02238334 -0.04049937 -0.00898643  0.00567498  0.00415353  0.04607487\n",
      " -0.01012934 -0.04284329 -0.00690025 -0.01919507  0.04377468  0.02403097\n",
      " -0.03815454  0.03079311 -0.03482682  0.0003893  -0.00257593 -0.02269059\n",
      " -0.02794855  0.05520518 -0.03158863 -0.01640644 -0.00925507 -0.03643204\n",
      "  0.02914174 -0.04651129  0.00032434  0.01573621 -0.031753   -0.05111977\n",
      " -0.04892673  0.04455487  0.05242945 -0.0211822  -0.02086334 -0.00768175]\n",
      "Evaluation of the Model\n",
      "7392/7440 [============================>.] - ETA: 0s4652591.68387\n",
      "Saving the Weights\n"
     ]
    }
   ],
   "source": [
    "n_words = len(words)\n",
    "n_embed_dims = 150\n",
    "\n",
    "# put together a model to predict\n",
    "input_sentence = Input(shape=(max_len,), dtype='int32')\n",
    "input_embedding = Embedding(n_words, n_embed_dims)(input_sentence)\n",
    "output = SimpleRNN(max_len)(input_embedding)\n",
    "\n",
    "model = Model(inputs=[input_sentence], outputs=[output])\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# fit the model to predict what color each person is\n",
    "model.fit(dataX, dataY, epochs=2, verbose=3)\n",
    "embeddings = model.layers[1].get_weights()\n",
    "\n",
    "# print out the embedding vector associated with each word\n",
    "for i in range(2):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[0][i]))\n",
    "    \n",
    "print \"Evaluation of the Model\"\n",
    "print model.evaluate(dataX, dataY)\n",
    "print \"Saving the Weights\"\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Training For The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 2/20\n",
      "Epoch 3/20\n",
      "Epoch 4/20\n",
      "Epoch 5/20\n",
      "Epoch 6/20\n",
      "Epoch 7/20\n",
      "Epoch 8/20\n",
      "Epoch 9/20\n",
      "Epoch 10/20\n",
      "Epoch 11/20\n",
      "Epoch 12/20\n",
      "Epoch 13/20\n",
      "Epoch 14/20\n",
      "Epoch 15/20\n",
      "Epoch 16/20\n",
      "Epoch 17/20\n",
      "Epoch 18/20\n",
      "Epoch 19/20\n",
      "Epoch 20/20\n",
      "7328/7440 [============================>.] - ETA: 0s  0.0244942809986\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataX, dataY, epochs=20, batch_size=64, verbose=3)\n",
    "print \"  {}\".format(model.evaluate(dataX, dataY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Epoch 2/4\n",
      "Epoch 3/4\n",
      "Epoch 4/4\n",
      ": [ -7.52860755e-02  -4.54015285e-02  -4.58094329e-02   8.84827878e-03\n",
      "  -8.48692900e-04  -3.17476653e-02  -1.13650709e-02   6.56244531e-02\n",
      "   6.53840974e-03   6.65657148e-02  -2.31543127e-02  -3.21851298e-02\n",
      "  -5.29217646e-02   1.71483925e-03   1.58685390e-02   1.47633646e-02\n",
      "  -3.10055520e-02   2.67946278e-03  -4.41819243e-03   1.17825922e-02\n",
      "   3.26833390e-02   6.82228524e-03  -2.40664147e-02   1.81059614e-02\n",
      "   4.85693328e-02   4.03854847e-02   5.97351231e-02   2.43128533e-03\n",
      "  -2.56353430e-02   1.97669603e-02  -8.07724521e-03   6.48374995e-03\n",
      "  -6.76449202e-03   3.24921831e-02   8.01629853e-03   9.09802562e-04\n",
      "  -1.93910580e-02  -2.17047911e-02  -4.88672033e-02  -4.92293611e-02\n",
      "  -1.37611022e-02   4.78589945e-02   1.62587315e-02  -1.04369866e-02\n",
      "  -3.82489036e-03  -7.70846556e-04   6.44029975e-02   6.63364481e-04\n",
      "   3.35666910e-02  -5.23372591e-02   6.23806678e-02  -1.97675209e-02\n",
      "  -1.34685580e-02  -2.47143134e-02  -3.12603428e-03   3.02405693e-02\n",
      "  -5.43108303e-03  -4.86856047e-03  -6.16468256e-03  -6.56778291e-02\n",
      "   2.80749761e-02   1.68174058e-02   5.01717953e-03   3.28464657e-02\n",
      "   4.94441949e-02   5.38286706e-03  -5.35058379e-02   1.32295350e-02\n",
      "   5.36481803e-03   4.23565581e-02   4.10231277e-02   3.82129736e-02\n",
      "  -1.79277174e-02   7.41770416e-02   3.89268138e-02   6.30560368e-02\n",
      "   1.96178183e-02   2.58695558e-02   2.65420005e-02  -5.03315330e-02\n",
      "  -1.02500185e-01  -2.38070134e-02  -3.76419537e-02  -4.41217162e-02\n",
      "   3.43981870e-02   3.58078778e-02  -4.22149971e-02  -1.95316840e-02\n",
      "   6.25744089e-02   1.94089115e-02   3.71261649e-02  -6.18134066e-02\n",
      "  -1.24759059e-02  -2.72412086e-03   1.32394698e-03  -3.53833772e-02\n",
      "   3.20545696e-02  -1.27512626e-02   5.22488775e-03   7.34908879e-02\n",
      "  -7.43532702e-02  -5.41725941e-02  -5.96406125e-02  -4.04142924e-02\n",
      "  -5.90195432e-02  -5.93596809e-02  -9.64786485e-03  -4.89757955e-02\n",
      "   1.59669612e-02   5.90473264e-02  -2.10292041e-02   2.24312451e-02\n",
      "  -3.36811095e-02   1.33087020e-02   1.85255893e-02  -7.02643767e-02\n",
      "  -3.66767012e-02   4.34864201e-02  -7.00375140e-02   4.09763604e-02\n",
      "  -9.40893218e-03  -4.01273556e-03   5.62449582e-02   6.74005076e-02\n",
      "  -1.12204151e-02  -1.65602509e-02  -2.18027793e-02  -1.45977745e-02\n",
      "  -9.77925738e-05   4.88026515e-02   8.60865600e-03  -2.01022197e-02\n",
      "  -3.49305919e-03   1.82843823e-02   4.55038026e-02   2.97041107e-02\n",
      "   1.50327652e-03   2.96132974e-02   3.24154645e-02   4.52071764e-02\n",
      "   1.75824668e-03  -2.28237566e-02   2.75641773e-02  -1.31969843e-02\n",
      "  -1.74199846e-02  -3.88109609e-02  -4.10306118e-02  -4.51851543e-03\n",
      "  -1.29248491e-02   4.94936444e-02]\n",
      "raining: [  2.17662882e-02  -3.22358608e-02   3.84049192e-02  -1.48130795e-02\n",
      "  -3.91182229e-02   1.98821183e-02   7.26884883e-03   3.82590806e-04\n",
      "   4.33988962e-03   5.22758663e-02   3.38371918e-02  -1.85643565e-02\n",
      "  -5.12135774e-02   8.95453151e-03  -4.86068102e-03   2.92333923e-02\n",
      "   1.38899060e-02  -2.50524767e-02   1.46875326e-02  -1.88776404e-02\n",
      "   1.89123545e-02   3.74245308e-02  -1.69121902e-02   1.29888356e-02\n",
      "  -2.99088471e-02   4.72432673e-02   6.61857519e-03   2.40509436e-02\n",
      "  -2.48108860e-02   5.15524894e-02  -4.37095501e-02  -3.79354320e-02\n",
      "  -3.69691327e-02   2.84210201e-02   3.42914835e-02   3.90065983e-02\n",
      "  -5.20513654e-02   1.15966611e-02  -3.85929756e-02   1.01527646e-02\n",
      "  -1.03866849e-02   1.81655400e-02  -4.30043489e-02   2.68924739e-02\n",
      "  -4.16258052e-02   1.37270372e-02   3.36869285e-02  -4.07314412e-02\n",
      "  -4.08863984e-02  -2.18793787e-02  -2.93575600e-02  -4.42397520e-02\n",
      "  -6.75795600e-04   1.86134577e-02  -1.65594183e-02  -3.04894894e-02\n",
      "  -3.66011560e-02  -2.19888277e-02   1.81427728e-02   1.51306102e-02\n",
      "   4.40629758e-02  -3.66290063e-02   1.64120886e-02  -3.52665521e-02\n",
      "  -9.02011991e-04  -2.62715667e-02   2.34425012e-02  -1.82825290e-02\n",
      "   2.04689670e-02  -3.76056135e-02   3.86128090e-02  -4.91567254e-02\n",
      "   3.90621996e-03   1.20502263e-02  -8.91838595e-03   4.74537760e-02\n",
      "  -1.67961195e-02   1.09253358e-02  -3.39184166e-03  -8.19834508e-03\n",
      "  -3.14407721e-02   3.85490693e-02   3.05205770e-02   6.03682594e-03\n",
      "  -3.88378799e-02  -1.42913461e-02   3.43349129e-02   3.30614261e-02\n",
      "  -1.39089068e-02   1.76488087e-02   1.11607956e-02   3.96731421e-02\n",
      "  -5.02227107e-04  -3.56954783e-02   1.73275247e-02  -2.37809587e-03\n",
      "  -1.09385117e-03  -1.53382681e-03  -4.42829318e-02   5.17721511e-02\n",
      "  -8.31692014e-04   3.75299603e-02  -1.41658532e-02  -5.56084886e-02\n",
      "   3.05505767e-02  -3.90999690e-02  -9.46693402e-03  -3.58318165e-02\n",
      "   1.78119820e-02  -2.10042228e-03   2.00573895e-02  -3.01384013e-02\n",
      "  -5.02838604e-02  -3.62950400e-03  -3.50329140e-03  -3.84560376e-02\n",
      "   1.53800258e-02   4.02755104e-05   2.92134397e-02  -2.90230345e-02\n",
      "  -1.85889960e-03  -3.48939188e-02   3.96542735e-02  -1.00900168e-02\n",
      "   2.05992046e-03  -4.42526415e-02  -1.80659816e-02  -3.14899907e-02\n",
      "   3.56562808e-02   4.08458933e-02   1.63240619e-02   7.38642737e-03\n",
      "   2.14235988e-02   2.74679400e-02   1.06987488e-02   3.83791467e-03\n",
      "  -3.07810921e-02   2.81800386e-02  -1.72081366e-02  -2.60625910e-02\n",
      "   2.21095681e-02  -1.99711565e-02   2.62284791e-03   1.88709609e-02\n",
      "   3.98966074e-02  -4.55852263e-02   1.96404513e-02   8.03712383e-03\n",
      "   3.77115272e-02  -9.66952369e-03]\n",
      "7360/7440 [============================>.] - ETA: 0sEvaluation: -8155.56841923\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataX, dataY, epochs=4, batch_size=64, verbose=3)\n",
    "embeddings = model.layers[1].get_weights()\n",
    "\n",
    "# print out the embedding vector associated with each word\n",
    "for i in range(2):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[0][i]))\n",
    "\n",
    "print 'Evaluation: {}'.format(model.evaluate(dataX, dataY))\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to test the model with some custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        ,  0.        , -0.        ,  0.        ,  0.00316837,\n",
       "        -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "         0.08428954,  0.28899291,  0.        ,  0.        ,  0.        ,\n",
       "        -0.31553316,  0.03101788,  0.        ,  0.        , -0.        ,\n",
       "        -0.        ,  0.        ,  0.13992527, -0.11859532,  0.        ,\n",
       "         0.        ,  0.        ,  0.01655224, -0.        ,  0.03247942,\n",
       "        -0.        ,  0.01039564, -0.        ,  0.        ,  0.19620955,\n",
       "         0.        ,  0.        ,  0.18380126,  0.12647456, -0.        ,\n",
       "         0.        ,  0.29543972,  0.59864187,  0.29531297,  0.28910464,\n",
       "        -0.        ,  0.65704238,  0.83109629,  0.65468234,  0.56219828,\n",
       "        -0.        ,  0.46520701,  0.54404628,  1.        ,  0.70375729,\n",
       "         0.84097189,  1.        ,  1.        ,  1.        , -0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        , -0.        ,  1.        , -0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        -0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = [0] * (max_len - 3) + [word2idx['i'], word2idx['love'], word2idx['you']]\n",
    "model.predict(np.array(inp).reshape(1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Model\n",
    "This is how you export the model into a json file in order to be imported later. Then you export the model's weights. Later on in other experiments, you could effectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Model\n",
    "This is how you import the model from a json file and the weights so that you don't need to train it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
