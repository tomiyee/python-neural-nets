{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import h5py\n",
    "import numpy as np\n",
    "import string\n",
    "from keras.layers import Input, Embedding, merge, Flatten, Reshape, Lambda, LSTM\n",
    "import keras.backend as K\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#imports a massive dataset of sentences found on wikipedia\n",
    "with open('training_data.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line,\n",
    "# also strips the punctuation\n",
    "sentences = [x.strip().translate(None, string.punctuation) for x in content] \n",
    "\n",
    "lemma = lambda x: x.strip().lower().split(' ')\n",
    "sentences_lemmatized = [lemma(sentence) for sentence in sentences]\n",
    "words = set(itertools.chain(*sentences_lemmatized))\n",
    "# set(['boy', 'fed', 'ate', 'cat', 'kicked', 'hat'])\n",
    "\n",
    "# dictionaries for converting words to integers and vice versa\n",
    "word2idx = dict((v, i) for i, v in enumerate(words))\n",
    "idx2word = list(words)\n",
    "\n",
    "# convert the sentences a numpy array\n",
    "to_idx = lambda x: [word2idx[word] for word in x]\n",
    "sentences_idx = [to_idx(sentence) for sentence in sentences_lemmatized]\n",
    "# Sets the maximum word length of each sentence\n",
    "max_len = 100\n",
    "# If the sentence is too long, good by\n",
    "for i in range(len(sentences_idx)-1, -1, -1):\n",
    "    if len(sentences_idx[i]) > max_len:\n",
    "        print i\n",
    "        sentences_idx.pop(i)\n",
    "    elif len(sentences_idx[i]) < max_len:\n",
    "        sentences_idx[i] = [0] * (max_len - len(sentences_idx[i])) + sentences_idx[i]\n",
    "sentences_array = np.asarray(sentences_idx, dtype='int32')\n",
    "#TODO find a way to set all sentence lengths to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3148\n",
      "3727\n"
     ]
    }
   ],
   "source": [
    "print len(sentences_idx)\n",
    "print len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create and Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n",
      ": [ 0.22768036 -0.30545023  0.15748617  0.12116787  0.25562724 -0.14322321\n",
      "  0.46510711 -0.82245916 -0.00748514 -0.1725014   0.19422317 -0.3540535\n",
      "  0.04533504 -0.1709715   0.23732799 -0.02119593 -0.01821132 -0.15042126\n",
      " -0.20996323 -0.09170409 -0.09941154  0.1342641   0.080317    0.27862796\n",
      " -0.22305863 -0.27003989 -0.09139743  0.05239067 -0.09230861  0.39692953\n",
      " -0.31664157  0.0885366  -0.00908646 -0.08516192  0.02227044 -0.40142402\n",
      " -0.09521891 -0.26441506  0.06257357  0.13762209  0.06840464  0.24984865\n",
      "  0.23637372 -0.00488208  0.17689338  0.06371383 -0.04009209 -0.26894838\n",
      " -0.05601483 -0.23654029 -0.23629937  0.18170148 -0.77354193 -0.6420067\n",
      " -0.04488938 -0.17026472 -0.20397688  0.2029203   0.14102919 -0.06707714\n",
      " -0.51093739 -0.01170623 -0.07719655  0.01513869 -0.14947674 -0.06247335\n",
      " -0.13333124  0.15981765  0.10708557 -0.21898629 -0.15272275 -0.03815776\n",
      " -0.29000893  0.18754801 -0.26066262 -0.08281148  0.04643783 -0.22606333\n",
      " -0.35567439  0.22268556 -0.45400435  0.15298542  0.32475159  0.39742616\n",
      " -0.04877424  0.13296433 -0.11879789  0.25075758 -0.22969218  0.15310664\n",
      " -0.05486051  0.10653234  0.14826719  0.47437328 -0.54069263 -0.36689049\n",
      " -0.1863737   0.20678273 -0.62121856  0.1810029   0.15879194  0.24753213\n",
      " -0.14598441 -0.07525519 -0.00227559  0.00226385  0.16687988 -0.36522806\n",
      "  0.07241997 -0.03051128  0.10359865 -0.1175686   0.04460692 -0.09530555\n",
      " -0.08254708 -0.0198647  -0.02207586 -0.1249105  -0.2792266   0.244348\n",
      "  0.07892063  0.26141727  0.01045625  0.14357243  0.35878012 -0.61844528\n",
      " -0.13757911  0.11332738  0.47926822  0.33741158 -0.14920153 -0.10128348\n",
      " -0.21046539  0.04578913  0.06283171 -0.20079409  0.31802842  0.19561216\n",
      "  0.01543367 -0.3657445  -0.10795715  0.23774593  0.11262873  0.1914757\n",
      " -0.33377394  0.06938045 -0.16729982 -0.05271832 -0.27035058 -0.25462329]\n",
      "raining: [ 0.32535583 -0.07848035  0.14813884 -0.32557771  0.27825639 -0.04034907\n",
      "  0.26683038 -0.25426361  0.26874936 -0.07831284  0.17347345 -0.17069481\n",
      "  0.19649407  0.18164882  0.27962601  0.18036845  0.05415407 -0.28227612\n",
      " -0.20559281 -0.21496731 -0.10240644 -0.33934653  0.38353056  0.38381276\n",
      "  0.16931486 -0.25362363 -0.14802538  0.4027935  -0.36314514  0.32143059\n",
      " -0.17289132  0.11210059  0.25453177  0.35833719 -0.31401786  0.03166877\n",
      "  0.23766826 -0.29368502 -0.28778428 -0.13988458 -0.25732693  0.32023504\n",
      "  0.14965257  0.26431993  0.11384438  0.17752169  0.37404126 -0.25501001\n",
      " -0.3388024  -0.34796378 -0.38301054  0.30280334 -0.31824604 -0.29187116\n",
      "  0.38671428  0.28389394 -0.18053712  0.28898698  0.11780006  0.16812997\n",
      " -0.12882778  0.14072843 -0.29734823 -0.22007324 -0.10222371  0.14399408\n",
      " -0.10554136  0.14791523  0.11916789 -0.35999957 -0.35616863 -0.38725296\n",
      " -0.10485461  0.20797388 -0.02685966  0.3089973  -0.12928763 -0.35721341\n",
      " -0.05256581 -0.17626041 -0.16612671  0.116373    0.27000791  0.18335353\n",
      " -0.05717168 -0.15312977 -0.35319996  0.059407   -0.15334623  0.15987641\n",
      " -0.24396217  0.21205206  0.29096985  0.29944804 -0.2399191  -0.12544893\n",
      "  0.38352165  0.29129133 -0.12748495  0.20341372  0.16727616  0.25819248\n",
      " -0.11205908  0.159116   -0.37890974  0.13836004  0.23267651 -0.19024961\n",
      " -0.11826078 -0.20320733 -0.37348226 -0.07974989  0.3026695   0.02460893\n",
      " -0.04780454  0.01554344 -0.11342587 -0.13240758  0.13010943  0.16935588\n",
      " -0.25603673  0.07597876  0.23740025 -0.12762161  0.16370247 -0.24499778\n",
      " -0.17811428 -0.36964688  0.04718037  0.19700108  0.15842046 -0.26718622\n",
      " -0.31748465  0.24721366  0.11166357 -0.2138778   0.16447078  0.17649269\n",
      " -0.12220903 -0.02374497  0.10726503  0.15175082 -0.14870799  0.37525427\n",
      " -0.23082837  0.19719939  0.18750162 -0.17054632 -0.08766156 -0.32783565]\n"
     ]
    }
   ],
   "source": [
    "n_words = len(words)\n",
    "n_embed_dims = 150\n",
    "\n",
    "# put together a model to predict\n",
    "input_sentence = Input(shape=(max_len,), dtype='int32')\n",
    "input_embedding = Embedding(n_words, n_embed_dims)(input_sentence)\n",
    "output = LSTM(100)(input_embedding)\n",
    "\n",
    "model = Model(inputs=[input_sentence], outputs=[output])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "# fit the model to predict what color each person is\n",
    "model.fit([sentences_array[:len(sentences_array)-1]], [sentences_array[1:]], epochs=10, verbose=3)\n",
    "embeddings = model.layers[1].get_weights()\n",
    "\n",
    "# print out the embedding vector associated with each word\n",
    "for i in range(2):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "Epoch 2/40\n",
      "Epoch 3/40\n",
      "Epoch 4/40\n",
      "Epoch 5/40\n",
      "Epoch 6/40\n",
      "Epoch 7/40\n",
      "Epoch 8/40\n",
      "Epoch 9/40\n",
      "Epoch 10/40\n",
      "Epoch 11/40\n",
      "Epoch 12/40\n",
      "Epoch 13/40\n",
      "Epoch 14/40\n",
      "Epoch 15/40\n",
      "Epoch 16/40\n",
      "Epoch 17/40\n",
      "Epoch 18/40\n",
      "Epoch 19/40\n",
      "Epoch 20/40\n",
      "Epoch 21/40\n",
      "Epoch 22/40\n",
      "Epoch 23/40\n",
      "Epoch 24/40\n",
      "Epoch 25/40\n",
      "Epoch 26/40\n",
      "Epoch 27/40\n",
      "Epoch 28/40\n",
      "Epoch 29/40\n",
      "Epoch 30/40\n",
      "Epoch 31/40\n",
      "Epoch 32/40\n",
      "Epoch 33/40\n",
      "Epoch 34/40\n",
      "Epoch 35/40\n",
      "Epoch 36/40\n",
      "Epoch 37/40\n",
      "Epoch 38/40\n",
      "Epoch 39/40\n",
      "Epoch 40/40\n",
      ": [ 0.11421335 -0.34195298  0.14875346  0.05392836  0.12991706 -0.08618486\n",
      "  0.3999809  -0.76869971  0.08086126 -0.1251906   0.19270097 -0.33295441\n",
      "  0.01580019 -0.107577    0.22398964  0.01513089  0.01916151 -0.10624117\n",
      " -0.21605955 -0.08518127 -0.09194651  0.07388883  0.09137119  0.34587136\n",
      " -0.14142758 -0.31441748 -0.11817735  0.06454242 -0.01044466  0.35414076\n",
      " -0.29594794  0.06419433  0.0310028  -0.05063775 -0.04320068 -0.39009914\n",
      " -0.03575946 -0.3181591   0.00331741  0.05502221 -0.01571499  0.28125241\n",
      "  0.2991271   0.04922093  0.15767452  0.08121652 -0.08995173 -0.24789695\n",
      " -0.02888307 -0.14439987 -0.15232626  0.13371088 -0.68084735 -0.54639369\n",
      "  0.04044622 -0.09545264 -0.17135461  0.13229856  0.11866256 -0.00834815\n",
      " -0.55025458  0.04167302 -0.04161595 -0.03107077 -0.12525566 -0.02928587\n",
      " -0.13362119  0.16256034  0.04742898 -0.12641892 -0.20456624 -0.07778455\n",
      " -0.20315906  0.10658001 -0.28431529 -0.04294001  0.08193621 -0.11362008\n",
      " -0.33456483  0.22773947 -0.38409311  0.07415589  0.2389773   0.36360025\n",
      " -0.09322225  0.06369069 -0.1103681   0.21353863 -0.31516472  0.07126746\n",
      " -0.04196753  0.09328663  0.20129736  0.44864473 -0.46450129 -0.43696532\n",
      " -0.13640854  0.16661267 -0.60800695  0.09020828  0.17623697  0.16843991\n",
      " -0.07919539 -0.03340181 -0.02283431  0.05012256  0.06855354 -0.33751839\n",
      "  0.00793987 -0.07723643  0.20998545 -0.06664917  0.09156948 -0.0661555\n",
      " -0.08098172 -0.07170159 -0.07147374 -0.14345954 -0.28459159  0.18438749\n",
      "  0.00999841  0.24208771  0.01825759  0.06504462  0.40165028 -0.56613094\n",
      " -0.12148114  0.01162577  0.52233011  0.33371514 -0.13791302 -0.03957699\n",
      " -0.23152101 -0.04197169  0.03623776 -0.12141284  0.26151839  0.18999696\n",
      " -0.04312737 -0.36684957 -0.02487625  0.23616718  0.07643031  0.16328913\n",
      " -0.2808066   0.00840109 -0.07240859 -0.02737935 -0.26000315 -0.17013052]\n",
      "raining: [ 0.29864419 -0.09696342  0.15853344 -0.29536709  0.24555936 -0.06433079\n",
      "  0.25619069 -0.21427578  0.23524958 -0.08775501  0.16007997 -0.18408211\n",
      "  0.18832007  0.19466703  0.26610348  0.17249119  0.04638476 -0.25628147\n",
      " -0.21601541 -0.20910349 -0.12177978 -0.31889489  0.35076648  0.34728917\n",
      "  0.15667282 -0.22025163 -0.14331388  0.37759423 -0.34650588  0.28968605\n",
      " -0.15713179  0.10735013  0.23586725  0.32417083 -0.28555277  0.04466821\n",
      "  0.22272857 -0.27168581 -0.27647349 -0.13019022 -0.23294173  0.2975432\n",
      "  0.13927834  0.24122263  0.11348381  0.1422445   0.34076861 -0.23470806\n",
      " -0.31254283 -0.31032947 -0.3405908   0.26214021 -0.29515418 -0.24944896\n",
      "  0.35625318  0.24568796 -0.16680402  0.27213377  0.12622945  0.17312427\n",
      " -0.09684123  0.12028663 -0.26474586 -0.21775472 -0.09711643  0.14395712\n",
      " -0.11940713  0.14818835  0.10549591 -0.32079682 -0.33394912 -0.34786353\n",
      " -0.08674044  0.2249202  -0.0218843   0.27943629 -0.1089204  -0.32457098\n",
      " -0.04252564 -0.14880902 -0.15950488  0.11916897  0.23440942  0.16450921\n",
      " -0.08793314 -0.14055347 -0.32361898  0.06173094 -0.12396407  0.1651001\n",
      " -0.24393682  0.20708437  0.24994916  0.2714256  -0.22437221 -0.11738279\n",
      "  0.36523801  0.27787995 -0.12705973  0.201757    0.18526955  0.2543737\n",
      " -0.10606343  0.15273231 -0.34211975  0.13133021  0.23841333 -0.17439747\n",
      " -0.11598471 -0.1938858  -0.36408737 -0.11265096  0.29855689  0.01245719\n",
      " -0.04088683  0.00215595 -0.11298297 -0.12231775  0.10747956  0.18943541\n",
      " -0.2193795   0.10021528  0.23725408 -0.12250779  0.16430835 -0.24193338\n",
      " -0.17191027 -0.33470336  0.04399921  0.15781903  0.1287339  -0.25334653\n",
      " -0.29309982  0.21692158  0.10230072 -0.19057091  0.16217673  0.16634515\n",
      " -0.11569142 -0.03865322  0.09575487  0.14762935 -0.1375183   0.33156648\n",
      " -0.21494968  0.1821714   0.17671035 -0.14523263 -0.09610547 -0.29735717]\n"
     ]
    }
   ],
   "source": [
    "model.fit([sentences_array[:len(sentences_array)-1]], [sentences_array[1:]], epochs=40, batch_size=10, verbose=3)\n",
    "embeddings = model.layers[1].get_weights()\n",
    "\n",
    "# print out the embedding vector associated with each word\n",
    "for i in range(2):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        ,  0.        , -0.        ,  0.        ,  0.00316837,\n",
       "        -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "         0.08428954,  0.28899291,  0.        ,  0.        ,  0.        ,\n",
       "        -0.31553316,  0.03101788,  0.        ,  0.        , -0.        ,\n",
       "        -0.        ,  0.        ,  0.13992527, -0.11859532,  0.        ,\n",
       "         0.        ,  0.        ,  0.01655224, -0.        ,  0.03247942,\n",
       "        -0.        ,  0.01039564, -0.        ,  0.        ,  0.19620955,\n",
       "         0.        ,  0.        ,  0.18380126,  0.12647456, -0.        ,\n",
       "         0.        ,  0.29543972,  0.59864187,  0.29531297,  0.28910464,\n",
       "        -0.        ,  0.65704238,  0.83109629,  0.65468234,  0.56219828,\n",
       "        -0.        ,  0.46520701,  0.54404628,  1.        ,  0.70375729,\n",
       "         0.84097189,  1.        ,  1.        ,  1.        , -0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        , -0.        ,  1.        , -0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        -0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = [0] * 97 + [word2idx['i'], word2idx['love'], word2idx['you']]\n",
    "model.predict(np.array(inp).reshape(1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Model\n",
    "This is how you export the model into a json file in order to be imported later. Then you export the model's weights. Later on in other experiments, you could effectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Model\n",
    "This is how you import the model from a json file and the weights so that you don't need to train it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
