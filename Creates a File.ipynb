{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import math\n",
    "from random import random as random\n",
    "from random import randint\n",
    "\n",
    "# jupyter command - allows plots to show up\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "num_features = 3 # a, b and c\n",
    "num_target = 2\n",
    "\n",
    "matrix = np.zeros((num_samples,num_features + num_target))\n",
    "\n",
    "a_range = [-5, 5]\n",
    "b_range = [-40, 40]\n",
    "c_range = [-5, 5]\n",
    "d_range = [-40, 40]\n",
    "np.random.seed(1)\n",
    "def generate_numbers (index, num_samples=num_samples):\n",
    "    if i < num_samples / 5:\n",
    "        a = np.random.randint(a_range[0], a_range[1])\n",
    "        b = np.random.randint(b_range[0], b_range[1])\n",
    "        c = np.random.randint(c_range[0], c_range[1])\n",
    "        d = np.random.randint(d_range[0], d_range[1])\n",
    "    elif i < 2 * num_samples / 5:\n",
    "        a = 1\n",
    "        b = np.random.random() * (b_range[1] - b_range[0])\n",
    "        c = 1\n",
    "        d = np.random.random() * (d_range[1] - d_range[0])\n",
    "    else:\n",
    "        a = np.random.random() * (a_range[1] - a_range[0]) + a_range[0]\n",
    "        b = np.random.random() * (b_range[1] - b_range[0]) + b_range[0]\n",
    "        c = np.random.random() * (c_range[1] - c_range[0]) + c_range[0]\n",
    "        d = np.random.random() * (d_range[1] - d_range[0]) + d_range[0]\n",
    "    return a, b, c, d\n",
    "\n",
    "for i in range(num_samples):\n",
    "    a, b, c, d = generate_numbers(i)\n",
    "    \n",
    "    # b**2 - 4ac\n",
    "    root = (1.0 * a * d + 1.0 * b * c) ** 2 - 4.0 * a * c * b * d\n",
    "    \n",
    "    while abs(a) < 1 or abs(b) < 1 or abs(c) < 1 or abs(d) < 1 or (root < 0):\n",
    "        a, b, c, d = generate_numbers(i)\n",
    "    \n",
    "    matrix[i, 0] = 1.0 * a * c\n",
    "    matrix[i, 1] = 1.0 * a * d + 1.0 * b * c\n",
    "    matrix[i, 2] = 1.0 * b * d\n",
    "    matrix[i, 3] = -1.0 * b / a\n",
    "    matrix[i, 4] = -1.0 * d / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = matrix[:, :num_features]\n",
    "trainY = matrix[:, num_features:]\n",
    "trainX = trainX.reshape(num_samples, 1, num_features)\n",
    "trainY = trainY.reshape(num_samples, 1, num_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   -8.        ,   208.        , -1224.        ]],\n",
       "\n",
       "       [[   -4.        ,   -98.        ,  -220.        ]],\n",
       "\n",
       "       [[    3.        ,    59.        ,  -812.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[    6.86612703,    24.75171308,  -597.51243667]],\n",
       "\n",
       "       [[    5.81921288,   -14.48171807,  -326.37624256]],\n",
       "\n",
       "       [[   12.61024787,   123.96266915,   165.3648628 ]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29s - loss: 274.9561\n",
      "Epoch 2/10\n",
      "28s - loss: 235.3205\n",
      "Epoch 3/10\n",
      "28s - loss: 192.8261\n",
      "Epoch 4/10\n",
      "28s - loss: 159.8251\n",
      "Epoch 5/10\n",
      "28s - loss: 135.6493\n",
      "Epoch 6/10\n",
      "29s - loss: 123.4739\n",
      "Epoch 7/10\n",
      "32s - loss: 120.1427\n",
      "Epoch 8/10\n",
      "30s - loss: 116.1673\n",
      "Epoch 9/10\n",
      "29s - loss: 117.3622\n",
      "Epoch 10/10\n",
      "28s - loss: 111.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128623bd0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(1, num_features)))\n",
    "model.add(Dense(200, activation='tanh'))\n",
    "model.add(Dense(200, activation='tanh'))\n",
    "model.add(Dense(200, activation='tanh'))\n",
    "model.add(Dense(2))\n",
    "# optimizer = keras.optimizers.Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "# stochastic gradient descent\n",
    "# optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# Adadelta\n",
    "optimizer = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "# Adam\n",
    "# optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "0s - loss: 149.8293\n",
      "Epoch 2/50\n",
      "0s - loss: 95.0228\n",
      "Epoch 3/50\n",
      "0s - loss: 91.3999\n",
      "Epoch 4/50\n",
      "0s - loss: 90.4257\n",
      "Epoch 5/50\n",
      "0s - loss: 89.7961\n",
      "Epoch 6/50\n",
      "0s - loss: 89.2542\n",
      "Epoch 7/50\n",
      "0s - loss: 88.8087\n",
      "Epoch 8/50\n",
      "0s - loss: 88.4932\n",
      "Epoch 9/50\n",
      "0s - loss: 88.2559\n",
      "Epoch 10/50\n",
      "0s - loss: 88.0585\n",
      "Epoch 11/50\n",
      "0s - loss: 87.8836\n",
      "Epoch 12/50\n",
      "0s - loss: 87.6908\n",
      "Epoch 13/50\n",
      "0s - loss: 87.5503\n",
      "Epoch 14/50\n",
      "0s - loss: 87.4494\n",
      "Epoch 15/50\n",
      "0s - loss: 87.3461\n",
      "Epoch 16/50\n",
      "0s - loss: 87.2371\n",
      "Epoch 17/50\n",
      "0s - loss: 87.1345\n",
      "Epoch 18/50\n",
      "0s - loss: 87.0505\n",
      "Epoch 19/50\n",
      "0s - loss: 86.9704\n",
      "Epoch 20/50\n",
      "0s - loss: 86.9108\n",
      "Epoch 21/50\n",
      "0s - loss: 86.8476\n",
      "Epoch 22/50\n",
      "0s - loss: 86.8011\n",
      "Epoch 23/50\n",
      "0s - loss: 86.7519\n",
      "Epoch 24/50\n",
      "0s - loss: 86.7067\n",
      "Epoch 25/50\n",
      "0s - loss: 86.6549\n",
      "Epoch 26/50\n",
      "0s - loss: 86.6194\n",
      "Epoch 27/50\n",
      "0s - loss: 86.5758\n",
      "Epoch 28/50\n",
      "0s - loss: 86.5477\n",
      "Epoch 29/50\n",
      "0s - loss: 86.5102\n",
      "Epoch 30/50\n",
      "0s - loss: 86.4963\n",
      "Epoch 31/50\n",
      "0s - loss: 86.4693\n",
      "Epoch 32/50\n",
      "0s - loss: 86.4700\n",
      "Epoch 33/50\n",
      "0s - loss: 86.4525\n",
      "Epoch 34/50\n",
      "0s - loss: 86.4497\n",
      "Epoch 35/50\n",
      "0s - loss: 86.4065\n",
      "Epoch 36/50\n",
      "0s - loss: 86.4573\n",
      "Epoch 37/50\n",
      "0s - loss: 86.4269\n",
      "Epoch 38/50\n",
      "0s - loss: 86.3340\n",
      "Epoch 39/50\n",
      "0s - loss: 86.3578\n",
      "Epoch 40/50\n",
      "0s - loss: 85.8694\n",
      "Epoch 41/50\n",
      "0s - loss: 86.0016\n",
      "Epoch 42/50\n",
      "0s - loss: 86.6428\n",
      "Epoch 43/50\n",
      "0s - loss: 88.8127\n",
      "Epoch 44/50\n",
      "0s - loss: 86.0350\n",
      "Epoch 45/50\n",
      "0s - loss: 85.7009\n",
      "Epoch 46/50\n",
      "0s - loss: 85.8920\n",
      "Epoch 47/50\n",
      "0s - loss: 85.9928\n",
      "Epoch 48/50\n",
      "0s - loss: 85.5311\n",
      "Epoch 49/50\n",
      "0s - loss: 85.5528\n",
      "Epoch 50/50\n",
      "0s - loss: 85.4813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d384e10>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=50, batch_size=num_samples, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.61086869, -4.07214594]]], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([1,2,1]).reshape(1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
